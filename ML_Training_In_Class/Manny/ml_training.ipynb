{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02349c2d",
   "metadata": {},
   "source": [
    "# ML Training Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff0017c",
   "metadata": {},
   "source": [
    "## Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48a9885c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.model_selection import cross_validate, train_test_split\n",
    "# import mord\n",
    "\n",
    "from pathlib import Path\n",
    "import datetime as dt\n",
    "import pandas as pd\n",
    "import csv\n",
    "import json\n",
    "import uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "10606156",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: mord in /opt/anaconda3/lib/python3.12/site-packages (0.7)\n"
     ]
    }
   ],
   "source": [
    "!pip install mord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d7f6b8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mord "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "befedf37",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('../../spatial_cleaned_inspections.csv')\n",
    "df = pd.read_csv(path)\n",
    "\n",
    "df.drop(columns = ['latitude', 'longitude'], inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cab6dc5",
   "metadata": {},
   "source": [
    "### Modeling Notes:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c78921",
   "metadata": {},
   "source": [
    "#### A few options on binning:\n",
    "\n",
    "1. Regression on the raw score\n",
    "    - What it does: Predicts the exact numeric score (0–100+).\n",
    "    - Why it’s powerful: Uses the full continuum of the target, so you’re not discarding any nuance.\n",
    "    - Trade‑off: You have to choose your pass/fail or A/B/C thresholds after you fit the model (but you can even tune those thresholds on a hold‑out set).\n",
    "\n",
    "2. Ordinal‑aware multi‑class\n",
    "    - What it does: Predicts ordered buckets (e.g. A/B/C → 0/1/2) while explicitly modeling their order.\n",
    "    - Why it helps: You still collapse the score into 3 groups, but your loss function “knows” that mis‑predicting A→B is a smaller error than A→C. That extra structure often boosts classification performance versus treating classes as unrelated.\n",
    "\n",
    "3. Plain multi‑class\n",
    "    - What it does: Predicts A, B, or C as independent labels.\n",
    "    - Why it’s weaker: Loses both granularity (all within‑class differences) and ordering information.\n",
    "\n",
    "4. Binary (fail/pass)\n",
    "    - What it does: Predicts whether score ≥ 28.\n",
    "    - Why it’s simplest: Straightforward, but you throw out nearly all of the score’s information (e.g. you treat a 27 the same as a 0)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e30f736",
   "metadata": {},
   "source": [
    "#### A starting pathway for choosing the target approach:\n",
    "\n",
    "1. **Start simple with the binary flag**\n",
    "\n",
    "   * Create\n",
    "\n",
    "     ```python\n",
    "     df['failing'] = (df.score >= 28).astype(int)\n",
    "     ```\n",
    "   * Train a classifier (e.g. logistic regression or random forest) and evaluate ROC‑AUC / F1 on “fail.”\n",
    "   * You’ll get a baseline that directly answers “who fails?” with minimal fuss.\n",
    "\n",
    "2. **If you need more insight, step up to ordinal**\n",
    "\n",
    "   * Map scores into A/B/C:\n",
    "\n",
    "     ```python\n",
    "     bins = [ -1, 13, 27, float('inf') ]\n",
    "     labels = ['A','B','C']\n",
    "     df['grade'] = pd.cut(df.score, bins=bins, labels=labels)\n",
    "     ```\n",
    "   * Use an **ordinal** model (e.g. `statsmodels`’ OrdinalLogit) or transform into multiple binary tasks (cumulative link).\n",
    "   * This lets you exploit the fact that mis‐classifying A→B is “less wrong” than A→C.\n",
    "\n",
    "3. **Regression if you really care about exact scores**\n",
    "\n",
    "   * Predict `score` directly, then choose your cutoff(s) in post‑processing.\n",
    "   * You can even treat the cutoff as a hyperparameter and tune it on your validation set for best classification metrics.\n",
    "\n",
    "\n",
    "##### Why not jump straight to multi‑class/ordinal?\n",
    "\n",
    "* **Complexity**: True ordinal methods require special loss functions or libraries.\n",
    "* **Data needs**: More classes mean fewer examples per class, which can hurt performance.\n",
    "* **Interpretability**: Stakeholders often just want “pass/fail.”\n",
    "\n",
    "\n",
    "##### How ordinal vs. numeric thresholding differ\n",
    "\n",
    "* A **plain multi‑class tree** treats A, B, C as unrelated labels.  You’d need to encode order (e.g. A→0, B→1, C→2) and accept that your model is really doing regression on those integers.\n",
    "* A **true ordinal** approach (cumulative link models, ordinal forest, etc.) explicitly penalizes “distance” between predicted and true classes in its loss.\n",
    "\n",
    "\n",
    "**Bottom line:**\n",
    "\n",
    "* **If your goal is simply “which restaurants fail?”**, go with the binary flag at 28.\n",
    "* **If you want richer predictions on letter grade**, do the ordinal multi‑class next (but be aware you’ll need an ordinal‐aware method to fully exploit ordering).\n",
    "* **If you care about exact score predictions (and may want different thresholds later)**, build a regression model and threshold afterward."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5d97cd",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "115132c6",
   "metadata": {},
   "source": [
    "#### Classes To Help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3609463",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ML_Helper:\n",
    "    def __init__(self, df: pd.DataFrame):\n",
    "        self.df = df.copy()\n",
    "        self.target = 'score'\n",
    "\n",
    "    def pass_fail_bins(self) -> pd.DataFrame:\n",
    "        if self.target == 'score':    \n",
    "            self.df['failing'] = (self.df[self.target] >= 28).astype(int)\n",
    "            self.df.drop(columns = self.target, inplace = True)\n",
    "            self.target = 'failing'\n",
    "            return self\n",
    "        else:\n",
    "            print('Could not finish. Please ensure .ordinal_bins() has not already be run.')\n",
    "\n",
    "    def ordinal_bins(self) -> pd.DataFrame:\n",
    "        if self.target == 'score':\n",
    "            bins = [-1, 13, 27, float('inf')]\n",
    "            labels = [0, 1, 2]  # A=0, B=1, C=2\n",
    "            self.df['grade'] = pd.cut(self.df[self.target], bins = bins, labels = labels).astype(int)\n",
    "            self.df.drop(columns = [self.target], inplace = True)\n",
    "            self.target = 'grade'\n",
    "            return self\n",
    "        else:\n",
    "            print('Could not finish. Please ensure .pass_fail_bins() has not already be run.')\n",
    "\n",
    "    def target_split(self) -> tuple[pd.DataFrame, pd.Series]:\n",
    "        return self.df.drop(columns = [self.target]), self.df[self.target]\n",
    "\n",
    "\n",
    "class Log_Training:\n",
    "    '''\n",
    "        Logs experiments to a per-user CSV. Each row contains:\n",
    "        - timestamp (ISO)\n",
    "        - run_id (UUID4)\n",
    "        - model_name (class name)\n",
    "        - params (JSON dict)\n",
    "        - metrics (JSON dict)\n",
    "        - extra (JSON dict for anything else you want to track)\n",
    "    '''\n",
    "\n",
    "    def __init__(self, classmate_name: str, log_dir = Path('logs')):\n",
    "        self.classmate = classmate_name\n",
    "        log_dir.mkdir(exist_ok = True)\n",
    "        log_stem = f'{classmate_name}_models.csv'\n",
    "        self.log_path = log_dir / log_stem\n",
    "\n",
    "        # If the file doesn’t exist, write a header\n",
    "        # if not os.path.isfile(self.log_path):\n",
    "        if not self.log_path.is_file():\n",
    "            with open(self.log_path, 'w', newline='') as f:\n",
    "                writer = csv.writer(f)\n",
    "                writer.writerow(['timestamp','run_id','model_name','params','metrics','extra'])\n",
    "\n",
    "    def log(self,\n",
    "            model=None,\n",
    "            *,\n",
    "            model_name: str = None,\n",
    "            params: dict = None,\n",
    "            metrics: dict = None,\n",
    "            extra: dict = None\n",
    "        ):\n",
    "        '''\n",
    "        Write one experiment record.\n",
    "\n",
    "        If you pass a scikit‑learn–style `model`, its .get_params() will be recorded automatically.\n",
    "        Otherwise, supply model_name and params explicitly.\n",
    "        '''\n",
    "        # Determine the name\n",
    "        name = model_name or (model.__class__.__name__ if model is not None else '<unknown>')\n",
    "\n",
    "        # Get params\n",
    "        if params is None:\n",
    "            if model is not None and hasattr(model, 'get_params'):\n",
    "                params = getattr(model, 'get_params')\n",
    "            else:\n",
    "                try:\n",
    "                    params = getattr(model, '__dict__', {})\n",
    "                except:\n",
    "                    params = {}\n",
    "        # Default metrics/extra\n",
    "        metrics = metrics or {}\n",
    "        extra   = extra   or {}\n",
    "        row = [\n",
    "            dt.datetime.now(dt.UTC).isoformat(),\n",
    "            str(uuid.uuid4()),\n",
    "            name,\n",
    "            json.dumps(params,  separators=('',','':'), default=str),\n",
    "            json.dumps(metrics, separators=(',',':'), default=str),\n",
    "            json.dumps(extra,   separators=(',',':'), default=str),\n",
    "        ]\n",
    "\n",
    "        with open(self.log_path, 'a', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(row)\n",
    "\n",
    "        return None\n",
    "\n",
    "    def train_and_log_mord(self, X, y, test_size, **mord_kwargs):\n",
    "        Xtr, Xte, ytr, yte = train_test_split(X, y, test_size = test_size, stratify = y)\n",
    "        m = mord.LogisticIT(**mord_kwargs).fit(Xtr, ytr)\n",
    "        preds = m.predict(Xte)\n",
    "        metrics = {'accuracy': accuracy_score(yte, preds)}\n",
    "        self.log(model=m, metrics=metrics)\n",
    "        return print(metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38b58241",
   "metadata": {},
   "source": [
    "#### Using ML_Helper\n",
    "\n",
    "- Pass in a df to the constructor and save it to a variable of your choice: `ml = ML_Helper(df)`  \n",
    "\n",
    "- Call either `ml.pass_fail_bins()` or `ml.ordinal_bins()`, or neither for full score regression. You cannot call both, it won't work.  \n",
    "    + This step is to take our target variable (which is the inspection score) and either convert it to a pass fail, or to the letter grade  \n",
    "\n",
    "- Lastly, call `X, y = ml.target_split()` to get an automatic split of the X and y variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9b8261c",
   "metadata": {},
   "source": [
    "### Run Trainings Here!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f5d36282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Binary target distribution: failing\n",
      "0    178790\n",
      "1     85985\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Binary Model\n",
    "\n",
    "binary_helper = ML_Helper(df)\n",
    "binary_helper.pass_fail_bins()\n",
    "binary_X, binary_y = binary_helper.target_split()\n",
    "\n",
    "print (f\"Binary target distribution: {binary_y.value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70c3ed30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>zipcode</th>\n",
       "      <th>census_tract</th>\n",
       "      <th>camis_30191841</th>\n",
       "      <th>camis_40356018</th>\n",
       "      <th>camis_40356483</th>\n",
       "      <th>camis_40356731</th>\n",
       "      <th>camis_40357217</th>\n",
       "      <th>camis_40359480</th>\n",
       "      <th>camis_40359705</th>\n",
       "      <th>camis_40360045</th>\n",
       "      <th>...</th>\n",
       "      <th>nta_SI24</th>\n",
       "      <th>nta_SI25</th>\n",
       "      <th>nta_SI28</th>\n",
       "      <th>nta_SI32</th>\n",
       "      <th>nta_SI35</th>\n",
       "      <th>nta_SI36</th>\n",
       "      <th>nta_SI37</th>\n",
       "      <th>nta_SI45</th>\n",
       "      <th>nta_SI48</th>\n",
       "      <th>nta_SI54</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11354</td>\n",
       "      <td>87100</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11220</td>\n",
       "      <td>10400</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11378</td>\n",
       "      <td>51500</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10453</td>\n",
       "      <td>21501</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11231</td>\n",
       "      <td>7500</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28538 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   zipcode  census_tract  camis_30191841  camis_40356018  camis_40356483  \\\n",
       "0    11354         87100           False           False           False   \n",
       "1    11220         10400           False           False           False   \n",
       "2    11378         51500           False           False           False   \n",
       "3    10453         21501           False           False           False   \n",
       "4    11231          7500           False           False           False   \n",
       "\n",
       "   camis_40356731  camis_40357217  camis_40359480  camis_40359705  \\\n",
       "0           False           False           False           False   \n",
       "1           False           False           False           False   \n",
       "2           False           False           False           False   \n",
       "3           False           False           False           False   \n",
       "4           False           False           False           False   \n",
       "\n",
       "   camis_40360045  ...  nta_SI24  nta_SI25  nta_SI28  nta_SI32  nta_SI35  \\\n",
       "0           False  ...     False     False     False     False     False   \n",
       "1           False  ...     False     False     False     False     False   \n",
       "2           False  ...     False     False     False     False     False   \n",
       "3           False  ...     False     False     False     False     False   \n",
       "4           False  ...     False     False     False     False     False   \n",
       "\n",
       "   nta_SI36  nta_SI37  nta_SI45  nta_SI48  nta_SI54  \n",
       "0     False     False     False     False     False  \n",
       "1     False     False     False     False     False  \n",
       "2     False     False     False     False     False  \n",
       "3     False     False     False     False     False  \n",
       "4     False     False     False     False     False  \n",
       "\n",
       "[5 rows x 28538 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Encoding categorical variables for processing. \n",
    "# We combine X and Y temporarily to for clean transformation. \n",
    "\n",
    "df_binary = pd.concat([binary_X, binary_y], axis = 1)\n",
    "\n",
    "# Define categorical columns\n",
    "categorical_columns = ['camis', 'boro', 'cuisine', 'inspection_date', 'inspection_type', 'inspection_subtype',\n",
    "                    'action', 'violation_code', 'critical_flag', 'nta']\n",
    "\n",
    "# Hot-encode categorical columns. \n",
    "\n",
    "df_binary_encoded = pd.get_dummies(df_binary, columns = categorical_columns, drop_first = True)\n",
    "\n",
    "# Split the data back into target and features. \n",
    "\n",
    "binary_X_encoded = df_binary_encoded.drop(columns = ['failing'])\n",
    "binary_y_encoded = df_binary_encoded['failing']\n",
    "\n",
    "#Inspect data.\n",
    "\n",
    "binary_X_encoded.shape\n",
    "binary_X_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f28f4d",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel."
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCannot execute code, session has been disposed. Please try restarting the Kernel. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Split data intro training and testing sets. \n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(binary_X_encoded, binary_y_encoded, test_size = 0.2, random_state = 42, stratify = binary_y_encoded)\n",
    "\n",
    "# Initialize and fit the model. \n",
    "\n",
    "logistic_regression_model = LogisticRegression(max_iter = 200)\n",
    "logistic_regression_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2efd65f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the test set.\n",
    "\n",
    "y_predictions = logistic_regression_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18d8d8f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate our model.\n",
    "\n",
    "print(f'Accuracy: {accuracy_score(y_test, y_predictions)}')\n",
    "\n",
    "print(f'Classification Report: {classification_report(y_test, y_predictions)}')\n",
    "\n",
    "print(f'Confussion Matrix: {confusion_matrix(y_test, y_predictions)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb7282c",
   "metadata": {},
   "source": [
    "After every run, please make sure to run save_run() to save the results of your model training/experimentation to a CSV log."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "763ac45a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ml = ML_Helper(df)\n",
    "# ml.pass_fail_bins()\n",
    "# ml.ordinal_bins()\n",
    "X, y = ml.target_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f88dd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33b40c05",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
